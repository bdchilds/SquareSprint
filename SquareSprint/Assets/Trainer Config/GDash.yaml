behaviors:
  GDash: # Replace with the name of your behavior (agent group)
    trainer_type: ppo
    hyperparameters:
      batch_size: 32        # Adjust based on your hardware and training requirements
      buffer_size: 2048     # Adjust based on your available memory
      learning_rate: 3.0e-4 # You can experiment with different learning rates
      epsilon: 0.2          # PPO clip parameter
      num_epoch: 3
      num_layers: 2
      hidden_units: 64
      max_steps: 1.0e5      # Adjust as needed
      time_horizon: 1024    # You can increase this if necessary
      summary_freq: 1000    # Frequency of writing summaries (TensorBoard)
      use_recurrent: false
    network_settings:
      normalize: false      # No need to normalize for this simple game
      hidden_activation: "relu"
    reward_signals:
      extrinsic:
        gamma: 0.99
        strength: 1.0